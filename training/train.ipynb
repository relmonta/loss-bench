{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da07a307",
   "metadata": {},
   "source": [
    "# Training\n",
    "This notebook allows interactive training of the Vision Transformer model for statistical downscaling using different loss functions.\n",
    "\n",
    "Click the button below to run this notebook on Google Colab.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/relmonta/loss-bench/blob/main/training/train.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d89a0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# If you are using google colab clone the github repository\n",
    "\n",
    "try:\n",
    "    %cd /content\n",
    "    import google.colab\n",
    "    ! git clone https://github.com/relmonta/loss-bench.git\n",
    "    %cd loss-bench\n",
    "except:\n",
    "    pass\n",
    "# Assuming you are in the root directory of the repository\n",
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43010c41",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    %cd /content/loss-bench\n",
    "except:\n",
    "    # Assuming you are in the root directory of the repository\n",
    "    pass\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import yaml\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "from data.data_module import DatasetSetup\n",
    "from models.vision_transformer import VisionTransformer\n",
    "from training.lightning_module import DownscalingModel\n",
    "from models.losses import *\n",
    "from training.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e658e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"You are good to go !\")\n",
    "else:\n",
    "    print(\"You are not using a GPU. Please check your Google Colab execution setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f35fc8",
   "metadata": {},
   "source": [
    "\n",
    "### 1. User settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae367c44",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set experiment parameters here\n",
    "var_name = \"pr\"   # \"pr\" or \"uas\"\n",
    "criterion_name = \"mse\"   # e.g., \"mse\", \"mae\", \"ssim\", \"combo1\"\n",
    "apply_log = None   # set to \"true\" or \"false\" to override config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00677290",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf484f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_yaml(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "MAIN_DIR = os.getcwd()  # assume notebook root is project root\n",
    "exp_config = load_yaml(os.path.join(MAIN_DIR, 'configs', f'exp_config_{var_name}.yaml'))\n",
    "\n",
    "batch_size = exp_config['training']['batch_size']\n",
    "accumulate_grad_batches = exp_config['training']['accumulate_grad_batches']\n",
    "num_epochs = exp_config['training']['epochs']\n",
    "learning_rate = exp_config['training']['learning_rate']\n",
    "num_cpus = os.cpu_count()\n",
    "num_workers = min(exp_config['training']['num_workers'], num_cpus)\n",
    "\n",
    "print(f\"Training {var_name} with {criterion_name} for {num_epochs} epochs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4356c1",
   "metadata": {},
   "source": [
    "### 3. Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71803a1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "require_gamma_params = \"asym\" in criterion_name.lower()\n",
    "if \"nllbg\" in criterion_name.lower():\n",
    "    exp_config['data']['kwargs_train_val']['normalize'] = False\n",
    "    exp_config['data']['kwargs_train_val']['standardize'] = False\n",
    "\n",
    "if apply_log is not None:\n",
    "    exp_config['data']['kwargs_train_val']['apply_log'] = apply_log.lower() == \"true\"\n",
    "\n",
    "dss = DatasetSetup(exp_config, require_gamma_params=require_gamma_params)\n",
    "dss.setup()\n",
    "\n",
    "train_dataset = dss.get_train_ds()\n",
    "val_dataset = dss.get_val_ds()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                          num_workers=num_workers, shuffle=True, prefetch_factor=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                        num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f386259",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Model and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30737eb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_args = exp_config[\"model\"][\"params\"]\n",
    "model_args[\"bernoulli_gamma\"] = \"nllbg\" in criterion_name.lower()\n",
    "model = VisionTransformer(**model_args).cuda()\n",
    "\n",
    "# Load YAML config containing loss details (losses_var.yaml)\n",
    "loss_config = load_yaml(exp_config['training']['loss_config_path'])\n",
    "metrics = {}\n",
    "for metric_name in exp_config['training']['metrics']:\n",
    "    metric_args = loss_config['losses'].get(metric_name.lower(), {}) or {}\n",
    "    metrics[metric_name] = get_criterion(metric_name, **metric_args)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate,\n",
    "                        weight_decay=exp_config['training']['weight_decay'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e1d91",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load loss configuration\n",
    "\n",
    "loss_config = load_yaml(exp_config['training']['loss_config_path'])\n",
    "loss_args = loss_config['losses'].get(criterion_name.lower(), {}) or {}\n",
    "\n",
    "if criterion_name.lower().startswith('combo'):\n",
    "    # For combination losses, gather individual loss args\n",
    "    wargs_dict = {loss: loss_config['losses'].get(loss, {}) or {}\n",
    "                    for loss in loss_config['losses'][criterion_name][\"losses\"]}\n",
    "    loss_args['losses'] = wargs_dict\n",
    "    print(f\"Losses args: {wargs_dict}\")\n",
    "    criterion = get_criterion(\"combination\", **loss_args)\n",
    "    print(\n",
    "        f\"Training using a combination of : {[loss_config['display'][loss] for loss in loss_args['losses']] } losses\")\n",
    "else:\n",
    "    # For single losses, use args directly\n",
    "    criterion = get_criterion(criterion_name, **loss_args)\n",
    "    print(f\"Training using {loss_config['display'][criterion_name]} loss\")\n",
    "\n",
    "if require_gamma_params:\n",
    "    # Get asym params from train dataset\n",
    "    set_asym_params(criterion, train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbff3236",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Experiment setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4015ad",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "description = criterion_name\n",
    "if train_dataset.apply_log_flag:\n",
    "    description = \"log_\" + description\n",
    "\n",
    "weight_path = os.path.join(exp_config['training']['weights_path'], exp_config['name'])\n",
    "os.makedirs(weight_path, exist_ok=True)\n",
    "\n",
    "filename = f\"weights-{description}\"\n",
    "ckpt_path = os.path.join(weight_path, filename + \".ckpt\")\n",
    "\n",
    "if os.path.exists(ckpt_path):\n",
    "    os.remove(ckpt_path)\n",
    "    print(f\"Deleted old checkpoint: {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83ca05e",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Model wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f5f76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "downscaling_model = DownscalingModel(\n",
    "    model, criterion, optimizer, learning_rate, metrics=metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a739ef64",
   "metadata": {},
   "source": [
    "\n",
    "### 7. Logging & callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b9a14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tb_path = os.path.join(MAIN_DIR, 'training/logs/tensorboard/',\n",
    "                       exp_config['name'], description)\n",
    "if os.path.exists(tb_path):\n",
    "    os.system(f\"rm -rf {tb_path}/*\")\n",
    "    print(f\"Deleted old logs: {tb_path}\")\n",
    "\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=os.path.join(MAIN_DIR, 'training/logs/tensorboard/'),\n",
    "    name=exp_config['name'],\n",
    "    version=description\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=weight_path,\n",
    "    filename=filename,\n",
    "    save_top_k=1,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b675d5aa",
   "metadata": {},
   "source": [
    "\n",
    "### 8. Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4436b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=num_epochs,\n",
    "    devices='auto',\n",
    "    accelerator='auto',\n",
    "    precision=32,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=logger,\n",
    "    log_every_n_steps=1,\n",
    "    strategy='ddp_find_unused_parameters_true',\n",
    "    accumulate_grad_batches=accumulate_grad_batches,\n",
    "    num_sanity_val_steps=0,\n",
    "    detect_anomaly=False\n",
    ")\n",
    "\n",
    "trainer.fit(downscaling_model, train_loader, [val_loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce418a98",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
